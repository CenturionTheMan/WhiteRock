{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872719e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 19:58:33.657323: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-01 19:58:33.738645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-01 19:58:35.538349: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "import tabulate as tb\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras import Sequential, layers, optimizers, losses\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import os, random, numpy as np, tensorflow as tf\n",
    "from model import FinancialLSTMModel\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from custom_attention import CustomAttention\n",
    "\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"]=\"1\"\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"]=\"1\"\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8788a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = './../data/AAPL_1h.csv'\n",
    "DATE_COL = 'Datetime'\n",
    "\n",
    "SEQ_LENGTH = 90\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.000001\n",
    "EPOCHS = 100\n",
    "TEST_RATIO = 0.2\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "REPS = 10\n",
    "\n",
    "EXCLUDE_COLUMNS = ['Datetime', 'returns', 'direction'] \n",
    "FEATURES = [\n",
    "    # Price and Volume Data (Best with Standard Scaling)\n",
    "    ('Close', 'standard'),\n",
    "    ('High', 'standard'),\n",
    "    ('Low', 'standard'),\n",
    "    ('Open', 'standard'),\n",
    "    ('Volume', 'standard'),\n",
    "    ('log_returns', 'standard'),\n",
    "\n",
    "    # Momentum, Trend & Volatility Indicators (Best with Standard Scaling)\n",
    "    ('macd', 'standard'),\n",
    "    ('roc', 'standard'),\n",
    "    ('adx', 'standard'),\n",
    "    ('di_plus', 'standard'),\n",
    "    ('di_minus', 'standard'),\n",
    "    ('atr_14', 'standard'),\n",
    "    ('atr_20', 'standard'),\n",
    "    ('atr_5', 'standard'),\n",
    "    ('volume_zscore_50', 'standard'),\n",
    "    \n",
    "    # Moving Averages & Bands (Best with Standard Scaling)\n",
    "    ('ema_10', 'standard'),\n",
    "    ('ema_20', 'standard'),\n",
    "    ('ema_50', 'standard'),\n",
    "    ('ema_100', 'standard'),\n",
    "    ('ema_200', 'standard'),\n",
    "    ('bb_lower_20', 'standard'),\n",
    "    ('bb_middle_20', 'standard'),\n",
    "    ('bb_upper_20', 'standard'),\n",
    "    \n",
    "    # Indicators that are Bounded or Ratios (Best with MinMax Scaling)\n",
    "    ('rsi_14', 'minmax'),\n",
    "    ('rsi_28', 'minmax'),\n",
    "    ('rsi_50', 'minmax'),\n",
    "    ('rsi_7', 'minmax'),\n",
    "    ('stoch_k', 'minmax'),\n",
    "    ('stoch_d', 'minmax'),\n",
    "    ('close_pos', 'minmax'),         # Position of close within the bar\n",
    "    ('body_range_ratio', 'minmax'),  # Candle body size vs. total range\n",
    "    ('bb_width_20', 'minmax'),       # Bounded ratio: BB width as a fraction\n",
    "    \n",
    "    # Others\n",
    "    ('obv', 'standard'),\n",
    "    ('rolling_max_20', 'standard'),\n",
    "    ('rolling_min_20', 'standard'),\n",
    "    ('price_from_20d_high', 'standard'),\n",
    "]\n",
    "\n",
    "TARGET = 'direction'\n",
    "\n",
    "def build_hidden_layers1():\n",
    "    return [\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "        CustomAttention(name='attention_layer'),\n",
    "        \n",
    "        GlobalAveragePooling1D(name='context_vector_aggregation'),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95ed997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REPETITION 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 19:58:37.069039: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 19:58:37.423449: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc_roc: 0.4975 - balanced_accuracy: 0.3526 - loss: 1.0985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 19:58:45.678622: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - auc_roc: 0.4892 - balanced_accuracy: 0.3421 - loss: 1.0987 - val_auc_roc: 0.5000 - val_balanced_accuracy: 0.3207 - val_loss: 1.0972 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.4948 - balanced_accuracy: 0.3324 - loss: 1.0986 - val_auc_roc: 0.5000 - val_balanced_accuracy: 0.3225 - val_loss: 1.0967 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4966 - balanced_accuracy: 0.3503 - loss: 1.0986 - val_auc_roc: 0.5529 - val_balanced_accuracy: 0.3225 - val_loss: 1.0964 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4939 - balanced_accuracy: 0.3434 - loss: 1.0986 - val_auc_roc: 0.6059 - val_balanced_accuracy: 0.3207 - val_loss: 1.0961 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - auc_roc: 0.4918 - balanced_accuracy: 0.3395 - loss: 1.0986 - val_auc_roc: 0.6304 - val_balanced_accuracy: 0.3311 - val_loss: 1.0959 - learning_rate: 1.0000e-06\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - auc_roc: 0.4983 - balanced_accuracy: 0.3540 - loss: 1.0983\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4905 - balanced_accuracy: 0.3443 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3438 - val_loss: 1.0958 - learning_rate: 1.0000e-06\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.4896 - balanced_accuracy: 0.3501 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3405 - val_loss: 1.0958 - learning_rate: 5.0000e-07\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4925 - balanced_accuracy: 0.3470 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3232 - val_loss: 1.0958 - learning_rate: 5.0000e-07\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - auc_roc: 0.4980 - balanced_accuracy: 0.3464 - loss: 1.0985\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4929 - balanced_accuracy: 0.3481 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3319 - val_loss: 1.0959 - learning_rate: 5.0000e-07\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.4909 - balanced_accuracy: 0.3463 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3387 - val_loss: 1.0959 - learning_rate: 2.5000e-07\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.4929 - balanced_accuracy: 0.3490 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3300 - val_loss: 1.0959 - learning_rate: 2.5000e-07\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc_roc: 0.5005 - balanced_accuracy: 0.3583 - loss: 1.0984\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.2499999968440534e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.4958 - balanced_accuracy: 0.3460 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3314 - val_loss: 1.0959 - learning_rate: 2.5000e-07\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.4933 - balanced_accuracy: 0.3575 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3558 - val_loss: 1.0959 - learning_rate: 1.2500e-07\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4966 - balanced_accuracy: 0.3589 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3507 - val_loss: 1.0959 - learning_rate: 1.2500e-07\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - auc_roc: 0.4984 - balanced_accuracy: 0.3554 - loss: 1.0983\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.249999984220267e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4933 - balanced_accuracy: 0.3430 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3507 - val_loss: 1.0959 - learning_rate: 1.2500e-07\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - auc_roc: 0.4928 - balanced_accuracy: 0.3457 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3491 - val_loss: 1.0959 - learning_rate: 6.2500e-08\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4963 - balanced_accuracy: 0.3450 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3475 - val_loss: 1.0959 - learning_rate: 6.2500e-08\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - auc_roc: 0.4939 - balanced_accuracy: 0.3524 - loss: 1.0983\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.1249999921101335e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4927 - balanced_accuracy: 0.3395 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3475 - val_loss: 1.0959 - learning_rate: 6.2500e-08\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - auc_roc: 0.4941 - balanced_accuracy: 0.3543 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3475 - val_loss: 1.0959 - learning_rate: 3.1250e-08\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.4912 - balanced_accuracy: 0.3603 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3475 - val_loss: 1.0959 - learning_rate: 3.1250e-08\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - auc_roc: 0.4964 - balanced_accuracy: 0.3717 - loss: 1.0983\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5624999960550667e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4905 - balanced_accuracy: 0.3558 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 3.1250e-08\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.4909 - balanced_accuracy: 0.3483 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.5625e-08\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4902 - balanced_accuracy: 0.3641 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.5625e-08\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - auc_roc: 0.4873 - balanced_accuracy: 0.3541 - loss: 1.0984\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.812499980275334e-09.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4887 - balanced_accuracy: 0.3535 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.5625e-08\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - auc_roc: 0.4955 - balanced_accuracy: 0.3449 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 7.8125e-09\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4919 - balanced_accuracy: 0.3608 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 7.8125e-09\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - auc_roc: 0.5023 - balanced_accuracy: 0.3616 - loss: 1.0983\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.906249990137667e-09.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4979 - balanced_accuracy: 0.3532 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 7.8125e-09\n",
      "Epoch 28/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.4960 - balanced_accuracy: 0.3489 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 3.9062e-09\n",
      "Epoch 29/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4922 - balanced_accuracy: 0.3503 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 3.9062e-09\n",
      "Epoch 30/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - auc_roc: 0.4976 - balanced_accuracy: 0.3431 - loss: 1.0984\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9531249950688334e-09.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - auc_roc: 0.4969 - balanced_accuracy: 0.3470 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 3.9062e-09\n",
      "Epoch 31/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - auc_roc: 0.4914 - balanced_accuracy: 0.3528 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 1.9531e-09\n",
      "Epoch 32/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.4944 - balanced_accuracy: 0.3541 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.9531e-09\n",
      "Epoch 33/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc_roc: 0.5038 - balanced_accuracy: 0.3643 - loss: 1.0983\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 9.765624975344167e-10.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - auc_roc: 0.4982 - balanced_accuracy: 0.3493 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.9531e-09\n",
      "Epoch 34/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4910 - balanced_accuracy: 0.3484 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 9.7656e-10\n",
      "Epoch 35/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5005 - balanced_accuracy: 0.3557 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 9.7656e-10\n",
      "Epoch 36/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - auc_roc: 0.4901 - balanced_accuracy: 0.3615 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 9.7656e-10\n",
      "Epoch 37/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4906 - balanced_accuracy: 0.3526 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 9.7656e-10\n",
      "Epoch 38/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - auc_roc: 0.4979 - balanced_accuracy: 0.3839 - loss: 1.0983\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.882812487672084e-10.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4983 - balanced_accuracy: 0.3572 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 9.7656e-10\n",
      "Epoch 39/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4974 - balanced_accuracy: 0.3550 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 4.8828e-10\n",
      "Epoch 40/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.4961 - balanced_accuracy: 0.3507 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 4.8828e-10\n",
      "Epoch 41/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc_roc: 0.4935 - balanced_accuracy: 0.3688 - loss: 1.0983\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 2.441406243836042e-10.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - auc_roc: 0.4914 - balanced_accuracy: 0.3590 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 4.8828e-10\n",
      "Epoch 42/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4918 - balanced_accuracy: 0.3464 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 2.4414e-10\n",
      "Epoch 43/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4931 - balanced_accuracy: 0.3569 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 2.4414e-10\n",
      "Epoch 44/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - auc_roc: 0.4964 - balanced_accuracy: 0.3567 - loss: 1.0983\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.220703121918021e-10.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.4990 - balanced_accuracy: 0.3496 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 2.4414e-10\n",
      "Epoch 45/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4905 - balanced_accuracy: 0.3443 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.2207e-10\n",
      "Epoch 46/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4936 - balanced_accuracy: 0.3453 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.2207e-10\n",
      "Epoch 47/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - auc_roc: 0.5022 - balanced_accuracy: 0.3624 - loss: 1.0983\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.103515609590104e-11.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4975 - balanced_accuracy: 0.3611 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.2207e-10\n",
      "Epoch 48/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.4993 - balanced_accuracy: 0.3480 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 6.1035e-11\n",
      "Epoch 49/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - auc_roc: 0.4936 - balanced_accuracy: 0.3452 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 6.1035e-11\n",
      "Epoch 50/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - auc_roc: 0.4902 - balanced_accuracy: 0.3537 - loss: 1.0983\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.051757804795052e-11.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.4926 - balanced_accuracy: 0.3435 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 6.1035e-11\n",
      "Epoch 51/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.4961 - balanced_accuracy: 0.3501 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 3.0518e-11\n",
      "Epoch 52/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4956 - balanced_accuracy: 0.3561 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 3.0518e-11\n",
      "Epoch 53/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - auc_roc: 0.4926 - balanced_accuracy: 0.3639 - loss: 1.0983\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.525878902397526e-11.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - auc_roc: 0.4967 - balanced_accuracy: 0.3532 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 3.0518e-11\n",
      "Epoch 54/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - auc_roc: 0.4890 - balanced_accuracy: 0.3424 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3459 - val_loss: 1.0959 - learning_rate: 1.5259e-11\n",
      "Epoch 55/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - auc_roc: 0.4870 - balanced_accuracy: 0.3484 - loss: 1.0986 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 1.5259e-11\n",
      "Epoch 56/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc_roc: 0.4970 - balanced_accuracy: 0.3729 - loss: 1.0983\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 7.62939451198763e-12.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.4946 - balanced_accuracy: 0.3588 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 1.5259e-11\n",
      "Epoch 57/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.4909 - balanced_accuracy: 0.3584 - loss: 1.0987 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 7.6294e-12\n",
      "Epoch 58/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - auc_roc: 0.4934 - balanced_accuracy: 0.3587 - loss: 1.0985 - val_auc_roc: 0.6412 - val_balanced_accuracy: 0.3477 - val_loss: 1.0959 - learning_rate: 7.6294e-12\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 20:01:30.742218: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> results: {'accuracy': 0.18808777429467086, 'f1_score': 0.17054795486269406, 'balanced_accuracy': 0.3430555555555555, 'precision': np.float32(0.9166667), 'recall': np.float32(0.11660777), 'confusion_matrix': array([[ 66,   6,   0],\n",
      "       [426,  54,   0],\n",
      "       [ 74,  12,   0]])}\n",
      "--- REPETITION 2/10 ---\n",
      "Epoch 1/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc_roc: 0.5081 - balanced_accuracy: 0.3615 - loss: 1.0983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 20:01:41.110434: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc_roc: 0.5068 - balanced_accuracy: 0.3598 - loss: 1.0984 - val_auc_roc: 0.5000 - val_balanced_accuracy: 0.3327 - val_loss: 1.0979 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - auc_roc: 0.5014 - balanced_accuracy: 0.3577 - loss: 1.0985 - val_auc_roc: 0.5578 - val_balanced_accuracy: 0.3017 - val_loss: 1.0975 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.5033 - balanced_accuracy: 0.3542 - loss: 1.0984 - val_auc_roc: 0.5647 - val_balanced_accuracy: 0.3222 - val_loss: 1.0971 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc_roc: 0.5092 - balanced_accuracy: 0.3755 - loss: 1.0981\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - auc_roc: 0.5034 - balanced_accuracy: 0.3602 - loss: 1.0984 - val_auc_roc: 0.5794 - val_balanced_accuracy: 0.3388 - val_loss: 1.0968 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5071 - balanced_accuracy: 0.3482 - loss: 1.0984 - val_auc_roc: 0.5882 - val_balanced_accuracy: 0.3492 - val_loss: 1.0965 - learning_rate: 5.0000e-07\n",
      "Epoch 6/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc_roc: 0.5089 - balanced_accuracy: 0.3551 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3500 - val_loss: 1.0964 - learning_rate: 5.0000e-07\n",
      "Epoch 7/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - auc_roc: 0.5239 - balanced_accuracy: 0.3659 - loss: 1.0980\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5117 - balanced_accuracy: 0.3611 - loss: 1.0984 - val_auc_roc: 0.5961 - val_balanced_accuracy: 0.3478 - val_loss: 1.0962 - learning_rate: 5.0000e-07\n",
      "Epoch 8/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - auc_roc: 0.5038 - balanced_accuracy: 0.3506 - loss: 1.0984 - val_auc_roc: 0.5961 - val_balanced_accuracy: 0.3620 - val_loss: 1.0962 - learning_rate: 2.5000e-07\n",
      "Epoch 9/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - auc_roc: 0.5045 - balanced_accuracy: 0.3438 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3868 - val_loss: 1.0962 - learning_rate: 2.5000e-07\n",
      "Epoch 10/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - auc_roc: 0.5077 - balanced_accuracy: 0.3704 - loss: 1.0980\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.2499999968440534e-07.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.4977 - balanced_accuracy: 0.3596 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3763 - val_loss: 1.0962 - learning_rate: 2.5000e-07\n",
      "Epoch 11/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - auc_roc: 0.5116 - balanced_accuracy: 0.3549 - loss: 1.0983 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3665 - val_loss: 1.0963 - learning_rate: 1.2500e-07\n",
      "Epoch 12/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.5055 - balanced_accuracy: 0.3546 - loss: 1.0984 - val_auc_roc: 0.5931 - val_balanced_accuracy: 0.3751 - val_loss: 1.0963 - learning_rate: 1.2500e-07\n",
      "Epoch 13/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.5144 - balanced_accuracy: 0.3510 - loss: 1.0983 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3837 - val_loss: 1.0964 - learning_rate: 1.2500e-07\n",
      "Epoch 14/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - auc_roc: 0.5322 - balanced_accuracy: 0.3618 - loss: 1.0980\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.249999984220267e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5168 - balanced_accuracy: 0.3487 - loss: 1.0983 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3784 - val_loss: 1.0964 - learning_rate: 1.2500e-07\n",
      "Epoch 15/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.5061 - balanced_accuracy: 0.3690 - loss: 1.0983 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3688 - val_loss: 1.0964 - learning_rate: 6.2500e-08\n",
      "Epoch 16/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5041 - balanced_accuracy: 0.3632 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3680 - val_loss: 1.0964 - learning_rate: 6.2500e-08\n",
      "Epoch 17/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - auc_roc: 0.5196 - balanced_accuracy: 0.3796 - loss: 1.0980\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.1249999921101335e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - auc_roc: 0.5114 - balanced_accuracy: 0.3554 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3662 - val_loss: 1.0965 - learning_rate: 6.2500e-08\n",
      "Epoch 18/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - auc_roc: 0.5071 - balanced_accuracy: 0.3413 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3703 - val_loss: 1.0965 - learning_rate: 3.1250e-08\n",
      "Epoch 19/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc_roc: 0.5088 - balanced_accuracy: 0.3684 - loss: 1.0983 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3730 - val_loss: 1.0965 - learning_rate: 3.1250e-08\n",
      "Epoch 20/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - auc_roc: 0.5258 - balanced_accuracy: 0.3751 - loss: 1.0980\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5624999960550667e-08.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - auc_roc: 0.5117 - balanced_accuracy: 0.3530 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3771 - val_loss: 1.0965 - learning_rate: 3.1250e-08\n",
      "Epoch 21/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - auc_roc: 0.5097 - balanced_accuracy: 0.3532 - loss: 1.0984 - val_auc_roc: 0.5951 - val_balanced_accuracy: 0.3712 - val_loss: 1.0965 - learning_rate: 1.5625e-08\n",
      "Epoch 22/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - auc_roc: 0.5155 - balanced_accuracy: 0.3515 - loss: 1.0983 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3712 - val_loss: 1.0965 - learning_rate: 1.5625e-08\n",
      "Epoch 23/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - auc_roc: 0.5258 - balanced_accuracy: 0.3556 - loss: 1.0981\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.812499980275334e-09.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc_roc: 0.5118 - balanced_accuracy: 0.3551 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3712 - val_loss: 1.0965 - learning_rate: 1.5625e-08\n",
      "Epoch 24/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - auc_roc: 0.5026 - balanced_accuracy: 0.3695 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3753 - val_loss: 1.0965 - learning_rate: 7.8125e-09\n",
      "Epoch 25/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - auc_roc: 0.5097 - balanced_accuracy: 0.3505 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3753 - val_loss: 1.0965 - learning_rate: 7.8125e-09\n",
      "Epoch 26/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - auc_roc: 0.5058 - balanced_accuracy: 0.3827 - loss: 1.0981\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.906249990137667e-09.\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - auc_roc: 0.5004 - balanced_accuracy: 0.3607 - loss: 1.0984 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3753 - val_loss: 1.0965 - learning_rate: 7.8125e-09\n",
      "Epoch 27/100\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - auc_roc: 0.5089 - balanced_accuracy: 0.3634 - loss: 1.0983 - val_auc_roc: 0.5941 - val_balanced_accuracy: 0.3694 - val_loss: 1.0965 - learning_rate: 3.9062e-09\n",
      "Epoch 28/100\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - auc_roc: 0.5072 - balanced_accuracy: 0.3805 - loss: 1.0980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m model.prepare_data()\n\u001b[32m     22\u001b[39m model.build_model(build_hidden_layers1())\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m ev = model.evaluate()\n\u001b[32m     25\u001b[39m res.append(ev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/src/model.py:209\u001b[39m, in \u001b[36mFinancialLSTMModel.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m callbacks = [\n\u001b[32m    203\u001b[39m     tf.keras.callbacks.ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.5\u001b[39m, patience=\u001b[32m3\u001b[39m, verbose=VERBOSE),\n\u001b[32m    204\u001b[39m     tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_balanced_accuracy\u001b[39m\u001b[33m'\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m45\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m    205\u001b[39m ]\n\u001b[32m    207\u001b[39m val = (\u001b[38;5;28mself\u001b[39m.X_val, \u001b[38;5;28mself\u001b[39m.y_val) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.val_split > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28mself\u001b[39m.history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVERBOSE\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HDD/Univerity/WhiteRock/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for r in range(REPS):\n",
    "    print(f\"--- REPETITION {r+1}/{REPS} ---\")\n",
    "    model = FinancialLSTMModel(\n",
    "        csv_path=CSV_PATH,\n",
    "        features_scales=FEATURES,\n",
    "        target_col=\"direction\",\n",
    "        datetime_col=\"Datetime\",\n",
    "\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        test_ratio=TEST_RATIO,\n",
    "        val_split=VAL_SPLIT,\n",
    "        weight_adj_factors=[1,1,1],\n",
    "        under_sample_imbalanced=True\n",
    "    )\n",
    "\n",
    "    model.prepare_data()\n",
    "    model.build_model(build_hidden_layers1())\n",
    "    model.train()\n",
    "    ev = model.evaluate()\n",
    "    res.append(ev)\n",
    "    \n",
    "    print(f\">> results: {ev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "+---+---------------------+---------------------+--------------------+--------------------+---------------------+------------------+\n",
      "|   |      accuracy       |      f1_score       | balanced_accuracy  |     precision      |       recall        | confusion_matrix |\n",
      "+---+---------------------+---------------------+--------------------+--------------------+---------------------+------------------+\n",
      "| 0 | 0.13793103448275862 | 0.07926919532839061 | 0.3326388888888889 | 0.8846153616905212 | 0.04063604399561882 |  [[ 69   3   0]  |\n",
      "|   |                     |                     |                    |                    |                     |   [461  19   0]  |\n",
      "|   |                     |                     |                    |                    |                     |  [ 82   4   0]]  |\n",
      "| 1 | 0.16927899686520376 | 0.1341421683943351  | 0.3536391042204996 | 0.8857142925262451 |  0.547703206539154  |  [[ 32   6  34]  |\n",
      "|   |                     |                     |                    |                    |                     |   [219  28 233]  |\n",
      "|   |                     |                     |                    |                    |                     |  [ 37   1  48]]  |\n",
      "| 2 | 0.20532915360501566 |  0.196026841342712  | 0.3481750645994832 | 0.8938053250312805 | 0.8922261595726013  |  [[ 12   5  55]  |\n",
      "|   |                     |                     |                    |                    |                     |   [ 45  53 382]  |\n",
      "|   |                     |                     |                    |                    |                     |  [ 16   4  66]]  |\n",
      "+---+---------------------+---------------------+--------------------+--------------------+---------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(res)\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(tb.tabulate(df, headers='keys', tablefmt='pretty', showindex=\"always\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
